# 深度学习

## 1.加深网络

### 1.1向更深的网络出发

​	创建如下图所示的CNN，这里卷积层全是3*3的小型滤波器，特点是随着层的加深，通道数变大(卷积层的通道数从前面的层开始按顺序以16、16、32、32、64、64的方式增加)。此外，插入了池化层，以逐渐减小中间数据的空间大小，并且后面的全连接层中使用了Dropout层。

![2](assets/2-1560242422005.JPG)

​	这个网络使用He初始值作为权重初始值，使用Adam更新权重参数。特点图下：

- 基于3*3的小型滤波器的卷积层
- 激活函数是ReLU
- 全连接层的后面使用Dropout层
- 使用He初始值作为权重初始值

这个学习过程很长，至少花费半天时间。

- 网络的实现源码：

~~~python
# coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定
import pickle
import numpy as np
from collections import OrderedDict
from common.layers import *


class DeepConvNet:
    """识别率为99%以上的高精度的ConvNet

    网络结构如下所示
        conv - relu - conv- relu - pool -
        conv - relu - conv- relu - pool -
        conv - relu - conv- relu - pool -
        affine - relu - dropout - affine - dropout - softmax
    """
    def __init__(self, input_dim=(1, 28, 28),
                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},
                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},
                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},
                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},
                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},
                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},
                 hidden_size=50, output_size=10):
        # 初始化权重===========
        # 各层的神经元平均与前一层的几个神经元有连接（TODO:自动计算）
        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])
        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # 使用ReLU的情况下推荐的初始值
        
        self.params = {}
        pre_channel_num = input_dim[0]
        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):
            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])
            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])
            pre_channel_num = conv_param['filter_num']
        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)
        self.params['b7'] = np.zeros(hidden_size)
        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)
        self.params['b8'] = np.zeros(output_size)

        # 生成层===========
        self.layers = []
        self.layers.append(Convolution(self.params['W1'], self.params['b1'], 
                           conv_param_1['stride'], conv_param_1['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W2'], self.params['b2'], 
                           conv_param_2['stride'], conv_param_2['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Convolution(self.params['W3'], self.params['b3'], 
                           conv_param_3['stride'], conv_param_3['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W4'], self.params['b4'],
                           conv_param_4['stride'], conv_param_4['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Convolution(self.params['W5'], self.params['b5'],
                           conv_param_5['stride'], conv_param_5['pad']))
        self.layers.append(Relu())
        self.layers.append(Convolution(self.params['W6'], self.params['b6'],
                           conv_param_6['stride'], conv_param_6['pad']))
        self.layers.append(Relu())
        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))
        self.layers.append(Affine(self.params['W7'], self.params['b7']))
        self.layers.append(Relu())
        self.layers.append(Dropout(0.5))
        self.layers.append(Affine(self.params['W8'], self.params['b8']))
        self.layers.append(Dropout(0.5))
        
        self.last_layer = SoftmaxWithLoss()

    def predict(self, x, train_flg=False):
        for layer in self.layers:
            if isinstance(layer, Dropout):
                x = layer.forward(x, train_flg)
            else:
                x = layer.forward(x)
        return x

    def loss(self, x, t):
        y = self.predict(x, train_flg=True)
        return self.last_layer.forward(y, t)

    def accuracy(self, x, t, batch_size=100):
        if t.ndim != 1 : t = np.argmax(t, axis=1)

        acc = 0.0

        for i in range(int(x.shape[0] / batch_size)):
            tx = x[i*batch_size:(i+1)*batch_size]
            tt = t[i*batch_size:(i+1)*batch_size]
            y = self.predict(tx, train_flg=False)
            y = np.argmax(y, axis=1)
            acc += np.sum(y == tt)

        return acc / x.shape[0]

    def gradient(self, x, t):
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.last_layer.backward(dout)

        tmp_layers = self.layers.copy()
        tmp_layers.reverse()
        for layer in tmp_layers:
            dout = layer.backward(dout)

        # 设定
        grads = {}
        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):
            grads['W' + str(i+1)] = self.layers[layer_idx].dW
            grads['b' + str(i+1)] = self.layers[layer_idx].db

        return grads

    def save_params(self, file_name="params.pkl"):
        params = {}
        for key, val in self.params.items():
            params[key] = val
        with open(file_name, 'wb') as f:
            pickle.dump(params, f)

    def load_params(self, file_name="params.pkl"):
        with open(file_name, 'rb') as f:
            params = pickle.load(f)
        for key, val in params.items():
            self.params[key] = val

        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):
            self.layers[layer_idx].W = self.params['W' + str(i+1)]
            self.layers[layer_idx].b = self.params['b' + str(i+1)]

~~~

- 训练过程代码：

~~~python
# coding: utf-8
import sys, os
sys.path.append(os.pardir)  # 为了导入父目录而进行的设定
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist
from deep_convnet import DeepConvNet
from common.trainer import Trainer

(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)

network = DeepConvNet()  
trainer = Trainer(network, x_train, t_train, x_test, t_test,
                  epochs=20, mini_batch_size=100,
                  optimizer='Adam', optimizer_param={'lr':0.001},
                  evaluate_sample_num_per_epoch=1000)
trainer.train()

# 保存参数
network.save_params("deep_convnet_params.pkl")
print("Saved Network Parameters!")

~~~

​	这个网络的识别成功率很高，错误率只有0.62%

### 1.2 进一步提高识别精度

查询一个标题为"What is the class of this image?"的网站，排行了目前为止通过论文等渠道发表得针对各种数据集得方法的识别精度

http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html

​	参考排行榜中前几名的方法，可以发现一些提高识别精度的方法，例如集成学习、学习率衰减、Data Augmentation(数据扩充)等，尤其是Data Augmentation效果十分显著。

​	Data Augmentation基于算法"人为地"扩充给输入图像(训练图像)。例如对于输入图像，通过施加旋转、垂直或水平方向上的移动等微小变化，增加图像的数量。

![1](assets/1-1560253974558.JPG)

​	除了如上图所示变形之外，Data Augmentation还可以通过其他各种方法扩充图像，比如裁剪图像的"crop处理"、将图像左右翻转的"flip处理"等。一般的图像也可以施加亮度等外观上的变化、放大缩小等尺度上的变化。主要是这种方法简单。

### 1.3 加深层的动机

- **减少网络的参数数量**：和没有加深层的网络相比，加深了层的网络可以用更少的参数达到同样的水平(或更强)的表现力。

![1](assets/1-1560254721991.JPG)

![2](assets/2-1560254724652.JPG)

​	图8—5中滤波器为1个5*5的结构，共需要25个参数，而图8-6则需要两个3 *3的滤波器，参数个数为2 * 3 * 3 = 18个。

​	**叠加小型滤波器来加深网络的好处是可以减小参数数量，扩大感受野(receptive field,给神经元施加变化的某个局部空间区域)。并且，通过叠加层，将ReLU等激活函数加在卷积层的中间，进一步提高了网络的表现力。这是因为向网络中添加了基于激活函数的"非线性"表现力，通过非线性函数的叠加，可以表现更加复杂的东西。**

- **使学习更加高效：**通过加深层，可以减小学习数据，从而高效的进行学习。例如“狗”的识别问题，浅层网络解决这个问题时，卷积层需要一下子理解很多关于"狗"的特征。而通过加深网络，就可以分层次地分解需要学习的问题，最开始只需要学习边缘就好，这样就需要用较少的学习数据来高效地进行学习。
- **通过加深层，可以分层次地传递信息**：提取了边缘的层的下一层能够使用边缘的信息

## 2.深度学习的历史

### 2.1ImageNet

ImageNet是拥有超过100万张图像的数据集，包含各种各样的图像，每一张图像都关联了标签，每年都会举办使用这个数据集的ILSVRC图像识别大赛。下面介绍几个广为人知的深度学习网络

### 2.2 VGG

- 概念：由卷积层和池化层构成的基础的CNN

- 特点：将有权重的层(卷积层或全连接层)叠加至15层(或19层)，具备了深度(VGG16或VGG19)

- 注意：基于3*3的小型滤波器的卷积层的运算时连续进行的。如下图所示，重复进行"卷积层重叠2次到4次，再通过池化层将大小减半"的处理，最后经全连接层输出结果

  ![2](assets/2-1560914398774.JPG)

### 2.3 GoogLeNet

![3](assets/3-1560914739011.JPG)

​	矩形表示卷积层、池化层等。它的特点是网络不仅在纵向上有深度，横向上也有广度。横向上的"宽度"称为"Inception结构"，该结构使用了多个大小不同的滤波器(和池化)，最后再合并它们的结果。GoogLeNet的特征就是将这个结构用作一个构件(构成元素)。此外，再GoogleNet中，很多地方都是哦那个了大小为1*1的滤波器的卷积层，这个1 * 1的卷积运算通过在通道方向上减小大小，有助于减少参数和实现高速化处理。

### 2.4 ResNet

​	在深度学习中，过度地加深层地话，很多情况下学习将不能顺利进行，导致最终性能不佳。在ResNet中，为了解决这类问题，导入了"快捷结构"，这样随着层地加深，可以不断地提高性能。

​	快捷结构横跨(跳过)了输入数据的卷积层，将输入x合计到输出。如下所示，在连续的2层卷积层的输出F(x)变成了F(x)+x  。 通过引入这种快捷结构，即便加深层，也能高效地学习。这是因为**通过快捷结构，反向传播时信号可以无衰减地传递**

![4](assets/4-1560929776699.JPG)

- 快捷结构之时原封不动地传递数据，所以反向传播时会将来自上游的梯度 **原封不动地传向下游**。因此，基于快捷结构，不用担心梯度会变小(或变大)，能够向前一层传递"有意义地梯度"。通过这个快捷结构，之前因为加深层而导致地梯度变小地梯度消失问题就会有望得到解决。

![5](assets/5-1560930150564.JPG)



**实践中经常会灵活应用使用ImageNet这个巨大的数据集学习到的权重数据，这称为迁移学习，将学习完的权重(的一部分)复制到其他的神经网络，进行再学习(fine tuning)，**比如，准备一个和VGG相同结构的网络，把学习完的权重作为初始值，以新数据集为对象，进行再学习。迁移学习在手头数据集较小时非常有效。

## 3.深度学习的高速化

### 3.1 需要解决的问题

- 如何高速、高效地进行大量的乘积累加运算

### 3.2 基于GPU的高速化

### 3.3 分布式学习

​	Google的TensorFlow、微软的CNTK在开发过程中高度重视分布式学习。以大型数据中心的低延迟高吞吐网络作为支撑，基于这些框架的分布式学习呈现出惊人的效果。关于分布式学习的技术性内容，请参考TensorFlow的技术论文(白皮书)等

### 3.4 运算精度的位数缩减

​	深度学习的高速化中，除了计算量之外，内存容量、总线带宽等也有可能称为瓶颈。关于内存容量，需要考虑将大量的权重参数或中间数据放在内存中，关于总线带宽，当流经GPU(CPU)总线的数据超过某个限制时，就会称为瓶颈。因此，我们希望尽可能减少流经网络的数据的位数

## 4.深度学习的应用案例

### 4.1物体检测

​	物体检测是比物体识别更难得问题。物体识别时以整个图像为对象得，但是物体检测需要从图像中确定类别的位置，而且还有可能存在多个物体。

- R-CNN来进行物体检测

![6](assets/6-1560931585512.JPG)

​	从“2.候选区域的提取”和"3.CNN特征的计算"的处理部分。这里，首先(以某种方法)找到形似物体的区域，然后对提取出的区域应用CNN进行分类。R-CNN会将图像变形为正方形，或者在分类时使用SVM(支持向量机)，实际的处理也是这两个方法构成的。

​	R-CNN的前半部分的处理—候选区域的提取(发现形似目标物体的处理)中，可以使用计算机视觉领域内的各种方法。R-CNN的论文中使用了一种Selective Search的方法，最近还提出了一种基于CNN来进行候选区域提取的Faster R-CNN方法。Faster R-CNN使用一个CNN来完成所有的处理，使高速处理称为可能。

### 4.2图像分割

​	**图像分割是指在像素水平上对图像进行分类**。如下图所示，使用以像素为单元对各个对象分别着色的监督数据进行学习。然后在推理时，对输入图像的所有像素进行分类。

![7](assets/7-1560932263508.JPG)



​	要基于神经网络进行图像分割，最简单的方法就是以所有像素为对象，对每个像素执行推理处理。例如，准备一个对某个矩形区域中心的像素进行分类的网络，以所有像素为对象执行推理处理。这样的方法需要按照像素数量进行相应次forward处理，耗费大量时间(卷积运算中发生重复计算很多区域的无意义的计算)。因此，有人提出FCN的方法，通过一次forward处理，对所有像素进行分类。

​	FCN(全部由卷积层构成的网络)，FCN将全连接层替换成发挥相同作用的卷积层。在只由卷积层构成的网络中，空间容量可以保持原样直到最后的输出。

​	如下图，FCN的特征在于最后导入了扩大空间大小的处理。基于这个处理，变小了的空间数据可以一下子扩大到和输入图像一样的大小。FCN最后进行过的扩大处理是基于双线性插值法的扩大。FCN中，这个双线性插值扩大是通过去卷积(逆卷积运算)来实现的

![3](assets/3-1560933296746.JPG)

![4](assets/4-1560934317409.JPG)

### 4.3 图像标题的生成

![5](assets/5-1560934436962.JPG)

​	一个基于深度学习生成图像标题的代表性方法是被称为NIC，它由深层的CNN和处理自然语言的RNN构成。我们将组合图像和自然语言等多种信息进行的处理称为**多模态处理**

![6](assets/6-1560934622254.JPG)

## 5.深度学习的未来

### 5.1图像风格的变换

### 5.2 图像的生成

- DCGAN

### 5.3自动驾驶

- 基于CNN的神经网络SegNet

### 5.4 Deep Q-Network(强化学习)

- Deep Q-Network(DQN)

![7](assets/7-1560935309287.JPG)

## 6.总结：

- 对于大多数问题，都可以期待通过过加深网络来提高性能
- 在ILSVRC中，基于深度学习的方法独占鳌头，使用的网络也在深化
- VGG,GoogleNet,ResNet是几个著名的网络
- 基于GPU、分布式、位数精度的缩减，可以实现深度学习的高速化
- 深度学习(神经网络)不仅可以用于物体的识别，还可以用于物体检测、图像分割
- 深度学习的应用包括图像标题的生成、图像的生成、强化学习等。还可以应用于自动驾驶。